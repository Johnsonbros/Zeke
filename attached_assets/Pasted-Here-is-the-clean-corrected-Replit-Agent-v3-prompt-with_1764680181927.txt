Here is the clean, corrected Replit Agent v3 prompt with zero mentions of Housecall Pro, streamlined and ready to paste directly into Replit.

‚∏ª

üî• Replit Agent v3 Prompt (Voice Pipeline Only ‚Äì Clean Version)

You are Replit Agent 3 working on an existing project called ZEKE, a personal AI assistant for a single user (Nate).
Your job is to add a near real-time voice input pipeline using Limitless Pendant audio, and wire it cleanly into ZEKE‚Äôs existing ‚Äúbrain‚Äù so voice becomes a first-class input channel alongside SMS and web chat.

Your sole mission:
Make ZEKE the most powerful and useful AI assistant possible with a real-time(ish) voice interface.

‚∏ª

High-Level Requirements
	1.	Build a Limitless audio ‚Üí STT ‚Üí text ‚Üí ZEKE command pipeline that runs continuously in the background and feels close to real-time (~1‚Äì2 seconds delay).
	2.	Integrate voice commands into ZEKE using the same agent + tools logic already used for SMS/Web.
No separate ‚Äúvoice logic brain.‚Äù
	3.	Keep code modular, safe, incremental, and well-documented.

‚∏ª

Safety & Operational Constraints

DO NOT
	‚Ä¢	Delete or rename large directories.
	‚Ä¢	Drop or truncate databases.
	‚Ä¢	Perform destructive cleanups.
There have been real-world incidents of code agents wiping production data‚Äîavoid any action resembling that.

ALWAYS
	‚Ä¢	Add new modules instead of rewriting core ones.
	‚Ä¢	Summarize major changes before applying them.
	‚Ä¢	Keep all voice pipeline code isolated and pluggable.

‚∏ª

Step 1 ‚Äì Understand ZEKE‚Äôs Current Input Path
	1.	Scan the repo to find:
	‚Ä¢	Main server entrypoint.
	‚Ä¢	Where SMS/web messages are processed.
	‚Ä¢	How a ‚Äúuser message‚Äù is represented internally.
	2.	Create docs/voice_pipeline_notes.md summarizing:
	‚Ä¢	How text currently enters ZEKE.
	‚Ä¢	How voice text will reuse that same path.

Do not modify code in this step. Just document.

‚∏ª

Step 2 ‚Äì Add the Limitless Voice Ingest Service

Create a new module:
	‚Ä¢	Python: voice/limitless_listener.py
	‚Ä¢	TS/Node: src/voice/limitlessListener.ts

It will:

2.1 Environment Variables

Add support for:

LIMITLESS_API_BASE_URL (default: https://api.limitless.ai)
LIMITLESS_API_KEY
LIMITLESS_POLL_INTERVAL_MS (default: 800)

Document them in README.

2.2 Polling Logic

Use the endpoint:

GET /v1/download-audio?audioSource=pendant&startMs=X&endMs=Y

Constraints from YAML:
	‚Ä¢	Accepts Opus OGG audio.
	‚Ä¢	Requires startMs < endMs.
	‚Ä¢	Time window ‚â§ 2 hours.
	‚Ä¢	Max rate: 180 requests/min (~3/sec).
	‚Ä¢	On 429: back off using retryAfter.
	‚Ä¢	On 404: no audio for the window, just advance timestamps.

Implement:
	‚Ä¢	Maintain lastEndMs.
	‚Ä¢	On startup: lastEndMs = now - 1000ms.
	‚Ä¢	Every interval:
	‚Ä¢	startMs = lastEndMs
	‚Ä¢	endMs = now
	‚Ä¢	Fetch audio
	‚Ä¢	Push chunk to STT queue if exists
	‚Ä¢	Advance lastEndMs = endMs

2.3 Listener Interface

Example:

interface AudioChunk {
  startMs: number;
  endMs: number;
  data: Buffer;
}

type AudioHandler = (chunk: AudioChunk) => Promise<void>;

Listener runs in the background, feeding STT.

‚∏ª

Step 3 ‚Äì Add a Pluggable Transcription Layer

Add Transcriber interface:

interface Transcriber {
  transcribeChunk(chunk: AudioChunk): Promise<string>;
}

Implement a first version using OpenAI Whisper API:
	‚Ä¢	Accept raw audio/ogg bytes.
	‚Ä¢	Use a lightweight model (e.g., gpt-4o-mini-transcribe or similar).
	‚Ä¢	Return a transcript string.

This must be modular so we can later swap in Deepgram or local Whisper.

‚∏ª

Step 4 ‚Äì Add Utterance Detection & Wake Word Logic

Create UtteranceStream:

Responsibilities:
	‚Ä¢	Accumulate partial text for continuous chunks.
	‚Ä¢	Track last text time.
	‚Ä¢	When silence > ~1000ms ‚Üí treat collected text as a complete utterance.
	‚Ä¢	Require the wake word ‚ÄúZEKE‚Äù (case-insensitive) to treat the message as a command.
	‚Ä¢	Strip wake word before sending to ZEKE.

Example interface:

type UtteranceHandler = (utterance: {
  text: string;
  rawText: string;
  startedAt: number;
  endedAt: number;
}) => Promise<void>;

Add a timer that calls tick() every ~200ms.

‚∏ª

Step 5 ‚Äì Add Internal Voice ‚Üí ZEKE Command Endpoint

Create an internal route or function:

POST /internal/voice-command

Body example:

{
  "text": "remind me to call Nick at 5 PM",
  "rawText": "ZEKE remind me to call Nick at 5 PM",
  "source": "limitless_pendant",
  "startedAt": 1733153822333,
  "endedAt": 1733153828123
}

This handler should:
	1.	Convert the text into the SAME message format used by SMS/web inputs.
	2.	Feed it into the existing ZEKE agent and tools.
	3.	Log basic metadata (optional).

Do NOT create a separate agent for voice. Voice uses the same brain.

‚∏ª

Step 6 ‚Äì Wire Everything Together

In the main server startup:
	1.	Initialize Transcriber.
	2.	Initialize UtteranceStream.
	3.	Initialize LimitlessListener with:
	‚Ä¢	Audio handler: transcribe ‚Üí stream partial text.
	4.	Start:
	‚Ä¢	Listener loop
	‚Ä¢	Utterance tick timer
	5.	Ensure ZEKE still runs fine if Limitless is not configured (fail gracefully).

‚∏ª

Step 7 ‚Äì Documentation and Tests
	1.	Update README: ‚ÄúLimitless Voice Integration‚Äù
	2.	Add unit tests for:
	‚Ä¢	Utterance segmentation
	‚Ä¢	Wake word handling
	‚Ä¢	Poller URL construction
	3.	Add inline comments and docs/voice_pipeline_notes.md.

‚∏ª

Process Rules for the Agent
	‚Ä¢	Break work into small steps.
	‚Ä¢	Implement, test, then move to next step.
	‚Ä¢	Do NOT modify unrelated systems.
	‚Ä¢	Always explain major changes before applying them.

‚∏ª

End Goal

ZEKE should be able to hear Nate through the Limitless Pendant, transcribe the audio in near real-time, detect a full command, strip the wake word, and feed it into the normal agent ‚Üí tools pipeline‚Äîmaking voice a seamless, powerful input method.

‚∏ª

If you‚Äôd like, I can also give you:
	‚Ä¢	A compact ‚Äúsuper-short version‚Äù for the prompt,
	‚Ä¢	Or a version optimized for Replit Projects (their newer agent mode).